import json
import os
import threading
import time
import requests
import urllib
import random
from PIL import Image
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from win11toast import toast
from concurrent.futures import ThreadPoolExecutor


# è¦ç›‘è§†çš„æœç´¢å…³é”®è¯
searches = ["ã‚¯ãƒ‰ã‚ãµãŸãƒ¼", "ãƒ–ãƒ«ã‚¢ã‚«"]


######################################################################################
# è®¾ç½® Chrome é€‰é¡¹
chrome_options = Options()
chrome_options.add_argument("--headless")  # æ— å¤´æ¨¡å¼
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--log-level=3")
chrome_options.add_argument("--allow-insecure-localhost")
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36"
)


# **æ£€æŸ¥æ˜¯å¦è·³è½¬åˆ° search_condition_id= é¡µé¢**
def get_redirected_url(driver, search):
    try:
        WebDriverWait(driver, 15).until(EC.url_contains("search_condition_id="))
        return driver.current_url
    except Exception:
        print(
            f"å…³é”®è¯{search}\t âš ï¸å–µ~é¡µé¢æ²¡æœ‰è·³è½¬å“¦ï¼Œå¯èƒ½æ˜¯æ²¡æœ‰æ‰¾åˆ°å®è´æˆ–è€…è¢«æ‹¦ä½äº†æ(>_<)"
        )
        return None


# **é€šçŸ¥å‡½æ•°**
def download_image(image_url, search):
    """ä¸‹è½½å¹¶è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œé˜²æ­¢ Windows 11 Hero Image è£å‰ªï¼Œå¢žåŠ å¯¹ webp åŠ @webp çš„æ”¯æŒ"""
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        TEMP_DIR = os.path.join(search, "temp")
        os.makedirs(TEMP_DIR, exist_ok=True)

        # è§£æžåŽŸå§‹æ–‡ä»¶å
        original_name = (
            urllib.parse.urlparse(image_url).path.split("/")[-1].split("?")[0]
        )

        # å¦‚æžœæ–‡ä»¶åä¸­å¸¦æœ‰ @webp æˆ–ä»¥ .webp ç»“å°¾ï¼Œåˆ™ç»Ÿä¸€æ”¹æˆ .webp
        if "@webp" in original_name.lower():
            # æœ‰äº›æ–‡ä»¶åå¯èƒ½æ˜¯ ***.jpg@webp è¿™ç§å½¢å¼
            # è¿™é‡Œå°†å…¶ç»Ÿä¸€æ”¹ä¸º ***.webp
            base_name = original_name.lower().replace("@webp", "")
            if not base_name.endswith(".webp"):
                base_name = os.path.splitext(base_name)[0] + ".webp"
            image_name = base_name
        else:
            # è‹¥æœ«å°¾ç›´æŽ¥ä¸º .webp
            if original_name.lower().endswith(".webp"):
                image_name = original_name
            else:
                # å¦åˆ™ä¿æŒåŽŸåç§°
                image_name = original_name

        image_path = os.path.join(TEMP_DIR, image_name)

        # å¦‚æžœå›¾ç‰‡å·²å­˜åœ¨ï¼Œåˆ™ç›´æŽ¥è¿”å›žè·¯å¾„
        if os.path.exists(image_path):
            return os.path.abspath(image_path)

        # ä¸‹è½½å›¾ç‰‡
        response = requests.get(image_url, stream=True)
        if response.status_code == 200:
            with open(image_path, "wb") as file:
                for chunk in response.iter_content(1024):
                    file.write(chunk)
        else:
            print("âš ï¸å›¾ç‰‡ç¼“å­˜å¤±è´¥äº†å–µ~:", response.status_code)
            return None

        # ä½¿ç”¨ Pillow æ‰“å¼€å¹¶å¤„ç†å›¾ç‰‡
        with Image.open(image_path) as img:
            target_width = 453
            target_height = 223  # å¯ä»¥æŒ‰ç…§éœ€è¦è°ƒæ•´

            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            width_ratio = target_width / img.width
            height_ratio = target_height / img.height
            scale_ratio = min(width_ratio, height_ratio)

            # ç­‰æ¯”ç¼©æ”¾
            new_size = (int(img.width * scale_ratio), int(img.height * scale_ratio))
            resized_img = img.resize(new_size, Image.Resampling.LANCZOS)

            # åˆ›å»ºç™½è‰²èƒŒæ™¯ç”»å¸ƒ
            canvas = Image.new("RGB", (target_width, target_height), (255, 255, 255))

            # è®¡ç®—å±…ä¸­ç²˜è´´ä½ç½®
            paste_position = (
                (target_width - resized_img.width) // 2,
                (target_height - resized_img.height) // 2,
            )

            # å°†ç¼©æ”¾åŽçš„å›¾ç‰‡ç²˜è´´åˆ°ç”»å¸ƒå¹¶ä¿å­˜
            canvas.paste(resized_img, paste_position)
            canvas.save(image_path)

        return os.path.abspath(image_path)

    except Exception as e:
        print("âŒä¸‹è½½å›¾ç‰‡å‡ºé”™äº†å–µ~:", e)
        return None


def send_toast_notification(title, message, image, link, search):
    image_path = download_image(image, search)
    imagere = {"src": image_path, "placement": "hero"}
    toast(title, message, image=imagere, on_click=link)


# **æ£€æŸ¥æ‰€æœ‰å›¾ç‰‡æ˜¯å¦åŠ è½½å®Œæˆ**
def all_images_loaded(driver):
    img_elements = driver.find_elements(
        By.CSS_SELECTOR, ".imageContainer__f8ddf3a2 img"
    )
    loaded_count = sum(
        1
        for img in img_elements
        if img.get_attribute("src") and "https" in img.get_attribute("src")
    )
    print(f"âœ… å·²åŠ è½½ {loaded_count}/{len(img_elements)} å¼ å›¾ç‰‡äº†å“¦ï¼")
    return loaded_count == len(img_elements)


# **å¾ªçŽ¯ç›‘æŽ§æ–°å•†å“**
def get_search_url(search, stop_event):
    # æŒ‡å®š ChromeDriver è·¯å¾„
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=chrome_options,
    )
    # **åˆå§‹åŒ– search_condition_id= é¡µé¢**
    base_url = f"https://jp.mercari.com/search?keyword={search}"
    driver.get(base_url)
    search_url = get_redirected_url(driver, search) or base_url
    while not stop_event.is_set():
        # **è¯»å–æ—§æ•°æ®**
        os.makedirs(search, exist_ok=True)
        if os.path.exists(search + "/mercari_data.json"):
            with open(search + "/mercari_data.json", "r", encoding="utf-8") as f:
                old_items = json.load(f)
        else:
            with open(search + "/mercari_data.json", "w", encoding="utf-8") as f:
                json.dump([], f, ensure_ascii=False, indent=4)
            old_items = []

        old_item_ids = {item["id"] for item in old_items}
        # æž„é€ æ—§æ•°æ®çš„å­—å…¸ï¼Œä¾¿äºŽæŸ¥æ‰¾åŽ†å²ä»·æ ¼
        old_items_dict = {item["id"]: item for item in old_items}

        try:
            print(
                f"\n å…³é”®è¯{search}\t (=^ï½¥Ï‰ï½¥^=)=== åˆ·æ–°é¡µé¢å•¦~æ­£åœ¨åŠªåŠ›å—…æŽ¢æ–°å•†å“å–µ~ ==="
            )
            driver.get(search_url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "merItemThumbnail"))
            )

            # **ç¡®ä¿æ‰€æœ‰å›¾ç‰‡åŠ è½½å®Œæˆ**
            try:
                WebDriverWait(driver, 15).until(
                    EC.presence_of_all_elements_located(
                        (By.CLASS_NAME, "imageContainer__f8ddf3a2")
                    )
                )
                WebDriverWait(driver, 15).until(all_images_loaded)
                print(f"å…³é”®è¯{search}\t âœ… å–µå‘œ~æ‰€æœ‰å›¾ç‰‡éƒ½åŠ è½½å®Œæˆå•¦~(â‰§âˆ‡â‰¦)/")
            except Exception as e:
                print("âš ï¸å–µ~å›¾ç‰‡åŠ è½½å¤±è´¥å•¦ï¼Œå¯èƒ½æ˜¯ç½‘ç»œå¡ä½äº†å‘¢(ï¼›Â´Ð´ï½€)ã‚ž\n", e)
                continue

            # **æ£€æŸ¥ search_condition_id= æ˜¯å¦ä»ç„¶æœ‰æ•ˆ**
            current_search_url = get_redirected_url(driver, search)
            search_url = current_search_url if current_search_url else base_url

            # **æ£€æŸ¥å¹¶è®¾ç½®æŽ’åºæ–¹å¼**
            try:
                select_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "select__da4764db"))
                )
                select = Select(select_element)
                current_value = select.first_selected_option.get_attribute("value")

                if current_value != "created_time:desc":
                    print(f"å…³é”®è¯{search}\t ðŸ”„ åˆ‡æ¢æŽ’åºæ–¹å¼ä¸ºæœ€æ–°å“¦~è¯·ç¨ç­‰(à¹‘>á´—<à¹‘)")
                    select.select_by_value("created_time:desc")
                    WebDriverWait(driver, 5).until(EC.staleness_of(select_element))
                    WebDriverWait(driver, 10).until(all_images_loaded)
                else:
                    print(f"å…³é”®è¯{search}\t âœ… å·²ç»æ˜¯æœ€æ–°æŽ’åºå•¦~(Â´ï½¥Ï‰ï½¥`)")
            except Exception as e:
                print(f"å…³é”®è¯{search}\t âœ… å·²ç»æ˜¯æœ€æ–°æŽ’åºå•¦~(Â´ï½¥Ï‰ï½¥`)")

            # **èŽ·å–æ‰€æœ‰å•†å“ä¿¡æ¯**
            items = driver.find_elements(By.CLASS_NAME, "merItemThumbnail")
            new_items = []

            for item in items:
                try:
                    # èŽ·å–å•†å“ ID
                    item_id = item.get_attribute("id")

                    # èŽ·å–å•†å“åç§°
                    name_element = item.find_element(
                        By.CLASS_NAME, "itemName__a6f874a2"
                    )
                    item_name = name_element.text

                    # èŽ·å–ä»·æ ¼
                    price_element = item.find_element(By.CLASS_NAME, "number__6b270ca7")
                    item_price = price_element.text

                    # èŽ·å–å›¾ç‰‡é“¾æŽ¥
                    img_element = item.find_element(
                        By.CSS_SELECTOR, ".imageContainer__f8ddf3a2 img"
                    )
                    img_url = img_element.get_attribute("src")

                    # èŽ·å–å•†å“è¯¦æƒ…é¡µé“¾æŽ¥
                    link_element = item.find_element(
                        By.XPATH, "./ancestor::a[@data-testid='thumbnail-link']"
                    )
                    item_link = link_element.get_attribute("href")

                    # ä¿å­˜æ•°æ®
                    new_items.append(
                        {
                            "id": item_id,
                            "name": item_name,
                            "price": item_price,
                            "image": img_url,
                            "link": item_link,
                        }
                    )
                except Exception as e:
                    print(f"å…³é”®è¯{search}\t âš ï¸ ç­‰å¾…è§£æžå•†å“ä¿¡æ¯å–µ~(ï¼›Â´Ð´ï½€)ã‚ž\n")

            # **å¯¹æ¯”æ˜¯å¦æœ‰æ–°å•†å“**
            new_item_ids = {item["id"] for item in new_items}
            added_items = [item for item in new_items if item["id"] not in old_item_ids]

            # **è¾“å‡ºæ–°å¢žå•†å“**
            if added_items:
                print(
                    f"å…³é”®è¯{search}\t ðŸŽ‰å‘çŽ°{len(added_items)}ä¸ªæ–°å®è´å–µ~ï¼å¿«æ¥çœ‹çœ‹å˜›(à¹‘>á´—<à¹‘)"
                )
                for item in added_items:
                    print(f"ðŸŒ¸ã€{item['name']}ã€‘ - {item['price']}å††å–µ~")
                    print(f"ðŸ“¸ å›¾ç‰‡é“¾æŽ¥: {item['image']}\n")
                    print(f"ðŸ”— è¯¦æƒ…é¡µ: https://jp.mercari.com{item['link']}\n")

                    send_toast_notification(
                        f"å…³é”®è¯ {search} ðŸŽ‰æ–°å®è´æé†’å–µ~",
                        f"{item['name']} - {item['price']}",
                        item["image"],
                        item["link"],
                        search,
                    )
                old_item_ids.update(new_item_ids)

            for item in new_items:
                if item["id"] in old_items_dict:
                    try:
                        # å°†ä»·æ ¼æ–‡æœ¬è½¬ä¸ºæ•°å­—
                        old_price = float(
                            old_items_dict[item["id"]]["price"]
                            .replace("å††", "")
                            .replace(",", "")
                            .strip()
                        )
                        new_price = float(
                            item["price"].replace("å††", "").replace(",", "").strip()
                        )
                        if new_price < old_price:
                            print(
                                f"å…³é”®è¯{search}\t å–µå‘œ~å®è´ã€{item['name']}ã€‘é™ä»·å•¦~ä»Ž{old_price}å††å˜æˆ{new_price}å††å“¦ï¼Œèµ¶ç´§æ¡æ¼å˜›(â‰§Ï‰â‰¦)"
                            )
                            send_toast_notification(
                                f"å…³é”®è¯{search}\t ðŸ’°é™ä»·è­¦æŠ¥å–µï¼",
                                f"{item['name']} é™ä»·å•¦~\nåŽŸä»·:{old_price}å†† â†’ çŽ°ä»·:{new_price}å††\nä¸ä¹°ä¼šåŽæ‚”å“’~(*Â´âˆ€`)~â™¥",
                                item["image"],
                                item["link"],
                                search,
                            )

                    except Exception as e:
                        print("âš ï¸å–µå‘€~ä»·æ ¼è½¬æ¢å¤±è´¥ï¼Œçˆªå­ä¸å¥½ä½¿äº†(Â´ï¼›Ï‰ï¼›`)\n", e)

            with open(search + "/mercari_data.json", "w", encoding="utf-8") as f:
                json.dump(new_items, f, ensure_ascii=False, indent=4)

        except Exception as e:
            print("âŒå–µå‘œ~å‘ç”Ÿé”™è¯¯å•¦ï¼Œä¸»äººè¯·ç¨åŽå†è¯•å§(>_<)\n", e)

        delay = random.randint(1, 10)
        print(f"å–µå‘œ~{delay//60}åˆ†é’Ÿ{delay % 60}ç§’åŽå†æ¬¡æ£€æŸ¥å–µ~\n")
        time.sleep(delay)


# **Mercari æœç´¢é¡µé¢**
if __name__ == "__main__":

    # ç”¨äºŽæŽ§åˆ¶å­çº¿ç¨‹ç»“æŸçš„äº‹ä»¶
    stop_event = threading.Event()

    # åˆ›å»ºçº¿ç¨‹æ± å¹¶æäº¤ç›‘æŽ§ä»»åŠ¡
    with ThreadPoolExecutor(max_workers=len(searches)) as executor:
        futures = [
            executor.submit(get_search_url, search, stop_event) for search in searches
        ]
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\næ”¶åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œæ­£åœ¨å…³é—­æ‰€æœ‰ç›‘æŽ§çº¿ç¨‹â€¦")
            stop_event.set()  # é€šçŸ¥æ‰€æœ‰å­çº¿ç¨‹åœæ­¢
            # ç­‰å¾…å­çº¿ç¨‹æ‰§è¡Œç»“æŸ
            for future in futures:
                # æ­¤å¤„å¦‚æžœæœ‰éœ€è¦å¯ä»¥åš future.result() æ¥æ•èŽ·å­çº¿ç¨‹å¼‚å¸¸ä¿¡æ¯
                future.result()
